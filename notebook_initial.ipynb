{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS5014 Machine Learning\n",
    "\n",
    "Practical 1\n",
    "Credits: 50% of the coursework\n",
    "Deadline: 12/03/2025\n",
    "\n",
    "Note that MMS is the definitive source for deadlines and weights.\n",
    "\n",
    "\n",
    "Aims\n",
    "\n",
    "The objectives of this assignment are:\n",
    "\n",
    "    deepen your understanding of linear regression and logistic regression\n",
    "    gain experience in implementing learning algorithms\n",
    "    gain experience in evaluating machine learning algorithms\n",
    "\n",
    "\n",
    "Set-up\n",
    "\n",
    "You are only allowed to use the following imported packages for this practical. No off-the-shelf machine learning packages such as scikit-learn are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use jupyter-lab, switch to %matplotlib inline instead\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "%config Completer.use_jedi = False\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad    \n",
    "from autograd import hessian\n",
    "import autograd.numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method computes the gradient of a given function f at an input location initial. Note that the finite difference method suffers from truncating and rounding errors and can be slow for large-scale machine learning models. It should never be directly used in a gradient descent algorithm. But it can be very useful to check your gradient derivation and implementation. You should always check your gradients before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def finite_difference_gradient(f, initial, eps=1e-6):\n",
    "    initial = np.array(initial, dtype=float)\n",
    "    n = len(initial)\n",
    "    output = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        ei = np.zeros(n)\n",
    "        ei[i] = 1\n",
    "        f1 = f(initial + eps * ei)\n",
    "        f2 = f(initial - eps * ei)\n",
    "        output[i] = (f1-f2)/(2*eps)\n",
    "    output = output.reshape(n,1)\n",
    "    return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
